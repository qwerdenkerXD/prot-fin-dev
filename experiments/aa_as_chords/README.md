# Amino Acids as Chords

The idea of this experiment is to transform the protein sequences into sequences of chords.

As we are able to describe any amino acid as vector of floats representing their ten most identifying features,
with the help of the Kidera factors, it is possible to treat these vectors as musical chords of ten tones.

Therefore, every feature is assigned to one specific tone/frequency.
Now, with the amino acids' feature values influencing the volume/amplitude of these tones,
we get unique, comparable chords representing the amino acids' features.

When having the sequences transformed, it's just basic music recognition.

---
## Methods (`methods/*`)
<table>
    <th>method</th><th>steps</th>
    <tr>
        <td><code>get_aa_chords(file)</code></td>
        <td>
            <ol>
                <li>read kidera factor values for all amino acids from <code>file</code></li>
                <li>create vector of features' tones, starting from C4, increasing by a semitone step each</li>
                <li>extend value table with columns for symbols representing multiple amino acids, by forming the mean of the corresponding amino acids' vectors</li>
                <li>create a hashmap for each amino acid or special character in the table to its respective chord</li>
            </ol>
        </td>
    </tr>
    <tr>
        <td><code>create constellation(audio, sample_rate)</code></td>
        <td>
            <ol>
                <li>split audio evenly into pieces of 0.05 seconds (the duration of one tone)</li>
                <li>perform a stft on the pieces</li>
                <li>for each window find top peaks and add time and frequency to the constellation map (an array of these tuples)</li>
            </ol>
        </td>
    </tr>
    <tr>
        <td><code>create_hashes(constellation_map, song_id)</code></td>
        <td>
            <ol>
                <li>
                    for each time-frequency-pair in the map create combinatorial hashes (anker points) with the next 100 pairs of the map if their time index is between 1 and 10 above<br>
                    the hashes are generated by casting the frequency down to 10 bits integers and then combined into 32-bit int like: <br><code>(time-diff)-(frequency)-(freq_of_other_pair)</code>
                </li>
                <li>save time and song id for each hash</li>
            </ol>
        </td>
    </tr>
    <tr>
        <td><code>score_songs(hashes, database)</code></td>
        <td>
            <ol>
                <li>for each hash that occurs in the database, collect the matches and store the time from the sample and from the database per song id</li>
                <li>for each match in the stored matches per song, calculate the diff between source and sample time and count the occurences of each diff</li>
                <li>the score of a song is the max count of all diffs</li>
            </ol>
        </td>
    </tr>
    <tr>
        <td><code>create_db(prot_file)</code></td>
        <td>
            <ol>
                <li>create a database for all proteins in the file by joining the results of <code>create_hashes</code></li>
                <li>create a song-index-map as well to get to information for each song/protein</li>
            </ol>
        </td>
    </tr>
    <tr>
        <td><code>find_match(fasta_file)</code></td>
        <td>for each protein in the file, find the best scored match</td>
    </tr>
</table>

### Convenience Methods
`hashes_from_seq(seq, chord_map, song_id)`
 - just the workflow `seq_to_audio` $\rightarrow$ `create_constellation` $\rightarrow$ `create_hashes`

`seq_to_audio(seq, chord_map)`
 - transform the sequence into an array of chords

`get_wave(freq, duration)`
 - create vector of a sinus curve with the given frequence and duration and std amplitude of 4096

`iter_fasta(fasta_file)`
 - a generator function to iterate through the fasta file's contents

---
## Results (`results/*`)
|      file      |     content
|----------------|------------------
|initial_test.out|just a test of the basic functionality of the recognition<br>input was 6.5% of the original protein sequence of A0A1D8EJF9<br>the second match is the correct one

---
## Discussion/Brainstorming
The initial test gives a small evidence that the idea of this experiment works,
but the implementation is inspired by a song recognition algorithm.
So even if the protein sequences are here transformed to sound data,
they still behave differently than normal songs, e.g. because of less instruments or variance in volume or the way longer song length.

Some ideas for future development:
 - add appropriate testing
 - change some parameters
   - the anker points with the next `x` peaks
     - `x=100` is way too much for bigger databases, but the more points, the more information to identify shorter sequences more accurately
     - need to find a good compromise
   - window size when creating constellation map (does it need to be exactly one tone or can it be overlapping?)
 - check how to find similarity by specific kidera factors without recreating the database

---
## Environment

System: `Ubuntu 20.04.6 LTS`
Shell: `zsh 5.8`

| dependency | version |
|------------|---------|
|   python3  | 3.8.10  |
|    scipy   | 1.10.1  |
|    numpy   | 1.23.0  |
|   pandas   |  2.0.1  |
