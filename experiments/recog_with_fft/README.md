# Recognition with Fast Fourier Transformation <br> v0.4-exp-filter_hashes
`NOTE: This README and the code are updated synchronously.`

This experiment is to reduce database size, as it shouldn't be much higher than the train data.

Therefore, the created database will be filtered here to keep only the rarest hashes, as they have the highest information content anyway.

---

## Usage
1. go to `./methods`
2. create a database of reference proteins: `python3 protfin.py create-db <ref-fasta>`
3. find best scored matches for protein sequence samples: `python3 protfin.py find-matches <samples-fasta>`

### Tools
```sh
cd methods

# create a boxplot for protein counts for a hash, grouped by the hash's window distance
python3 evaluation.py plot-prots-per-windist database.pickle plot.png

# select sample proteins from different mapman bins
python3 evaluation.py select-samples mapmanreferencebins.results.txt protein.fa > samples.fa

# summarize protfin output
python3 evaluation.py eval protfin_out.csv > protfin_out.summary.csv

# summarize the *.summary.csv
python3 summary.py *.summary.csv

# generate a plot for counts of calculated hashes
TITLE="Distribution of sequences' hash counts" X_LABEL="Hash counts" \
Rscript raincloud_plot.R normal <(python3 evaluation.py print-hash-counts database.pickle) plot.png

# generate a plot for counts of proteins per hash with a log10 transformation
TITLE="Distribution of proteins per hash" X_LABEL="Protein counts" \
Rscript raincloud_plot_log10.R normal <(python3 evaluation.py print-prots-per-hash database.pickle) plot.png
```

### Unit Testing
To run the unit tests, just run the following:
```sh
cd methods
TQDM_DISABLE=1 python3 test.py
```

## Methods (`methods/*`)
<ul>
    <li>
        <details>
            <summary><code>protfin.py</code> - The tool that is going to be developed</summary>
            <table>
                <th>method</th><th>steps</th>
                <tr>
                    <td>actions.algorithm.kidera:<br><code>get_aa_vector(seq, factor, normalize, file)</code></td>
                    <td>
                        <ul><li>defaults: <code>normalize=True</code>, <code>file="../../../materials/Amino_Acid_Kidera_Factors.csv"</code></li></ul>
                        <ol type="1">
                            <li>normalize values by adding the global table mean if <code>normalize</code> is <code>True</code></li>
                            <li>extend value table with columns for symbols representing multiple amino acids, by forming the mean of the corresponding amino acids' vectors</li>
                            <li>extend value table with columns for non-valued amino acids 'O' and 'U', by treating their value as zero</li>
                            <li>transform the sequence and return it</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td>actions.algorithm.constellation:<br><code>create_constellation(aa_vec, window_size, n_peaks, window, **kwargs)</code></td>
                    <td>
                        <ul><li>defaults: <code>n_peaks=0</code>, <code>window="boxcar"</code>, <code>overlap@kwargs=window_size//2</code></li></ul>
                        <ol type="1">
                            <li>Initialize values: set <code>overlap=window_size-1</code> if it is bigger than window size</li>
                            <li>If input sequence is shorter than window size, return empty map</li>
                            <li>Do a STFT on <code>aa_vec</code> with the given parameters</li>
                            <li>for each STF-transformed window filter the amplitudes by the quantiles calculated in the sampling experiment</li>
                            <li>for each filtered amplitudes, get the n most prominent peaks as set by <code>n_peaks</code> or select all if <code>n_peaks=0</code></li>
                            <li>append all triples of peak (frequency index), its amplitude and quantile as one whole n-tuple to the constellation map, so one n-tuple per window with all its frequencies</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td>actions.algorithm.hash_gen:<br><code>create_hashes(constellation_map, prot_id, kidera_factor)</code></td>
                    <td>
                        <ol type="1">
                            <li>
                                for each frequency and its quantile in each window in the map create combinatorial hashes (anker points) with all upcoming frequencies in the next 2<sup>12</sup> windows:<br>
                                as frequencies use a max. of 5 bits each and the quantiles 1 bit each and the kidera factor 4 bits, the hashes are generated by combining them into a 32-bit int like: <br>
                                <code>(zeros)-(kidera_factor)-(quantile)-(other_quantile)-(index_diff)-(freq_of_other_pair)-(frequency)</code><br>
                                So currently there are 4 unused bits of zeros that can be assigned in further experiments.
                            </li>
                            <li>also, as the frequencies in the last window in the map doesn't have any upcoming frequencies to pair up with, they are combined with a dummy frequency that never exists (2<sup>5</sup>-1)
                            <li>save index and protein id for each hash</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td>actions.find_matches:<br><code>score_prots(hashes, database, protein_lookup)</code></td>
                    <td>
                        <ol type="1">
                            <li>for each hash, collect for each protein its offsets to its occurences in the protein sequence</li>
                            <li>for each protein, calculate its Jaccard Similarity Index (JSI)</li>
                            <li>the offset having the most matching occurences and the JSI form the score for a protein, as it is the best fitting constellation of the hashes</li>
                            <li>return the scores as Dictionary of protein identifiers pointing to their scores</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td>actions.create_db:<br><code>create_db(prot_file, db_out)</code></td>
                    <td>
                        <ol type="1">
                            <li>create a database for all proteins in the file by joining the results of <code>create_hashes</code></li>
                            <li>create a protein-lookup as well to get to the hash count for each protein</li>
                            <li>dump both into <code>db_out</code></li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td>actions.find_matches:<br><code>find_matches(fasta_file, db_in, filter_quantile)</code></td>
                    <td>
                        <ol type="1">
                            <li>filter the database hashes by <code>filter_quantile</code></li>
                            <li>for each protein in the file, find all match(es), using the database in <code>db_in</code>, and print them to stdout. The score consists of the custom score multiplied with the JSI</li>
                        </ol>
                    </td>
                </tr>
            </table>
            <h3>Convenience</h3>
            <code>actions.algorithm.hashes_from_seq(seq, prot_id)</code>
            <ul>
                <li>just the workflow <code>seq_to_vectors</code> $\rightarrow$ <code>create_constellation</code> $\rightarrow$ <code>create_hashes</code> for all kidera factors</li>
            </ul>
            <code>tools.Fasta(fasta_file)</code>
            <ul>
                <li>a class to iterate easily through the fasta file's contents with support of slicing, adding also a progress bar to indicate processed proteins</li>
                <li>currently not validating the file</li>
            </ul>
            <code>tools.count_appearances_in_file(pattern, file)</code>
            <ul>
                <li>used to count fastly e.g. the number of proteins in a file, which is necessary to create an appropriate progress bar</li>
            </ul>
            <code>tools.verify_type(val, ty)</code>
            <ul>
                <li>used in unit tests to easily and deeply verify a value's data type</li>
            </ul>
            <code>tools.pd_read_chunkwise(csv_file, chunksize)</code>
            <ul>
                <li>used for chunkwise iteration over the protfin output csv to reduce memory usage</li>
                <li>a returned item stores all matches of one input protein</li>
            </ul>
        </details>
    </li>
    <li>
        <details>
            <summary><code>evaluation.py</code> - Test prot-fin with training data and evaluate the results</summary>
            <table>
                <th>method</th><th>steps</th>
                <tr>
                    <td><code>evaluate_protfin(protfin_out_file)</code></td>
                    <td>
                        <ol type="1">
                            <li>for each output in <code>protfin_out_file</code>, extract the matches' data and count them</li>
                            <li>collect the input specific data from below the output</li>
                            <li>store everything into a dataframe and write it as csv to stdout</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td><code>select_samples(mapman, protein_file, samples_per_family)</code></td>
                    <td>
                        <ol type="1">
                            <li>identify the protein families in <code>mapman</code> file</li>
                            <li>for each family, select randomly <code>samples_per_family</code> proteins</li>
                            <li>find the selected proteins in <code>protein_file</code> and write them as new FASTA formatted output to stdout</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td><code>print_hash_counts(database)</code></td>
                    <td>
                        <ol type="1">
                            <li>Extract the hash counts from the protein lookup in <code>database</code></li>
                            <li>Print the extracted values comma separated to stdout</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td><code>print_prots_per_hash(database)</code></td>
                    <td>
                        <ol type="1">
                            <li>Extract the counts of proteins per hash from the <code>database</code></li>
                            <li>Print the extracted values comma separated to stdout</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td><code>plot_frequencies(prot_file, out_file, cpu_count)</code></td>
                    <td>
                        <ol type="1">
                            <li>Create the constellation maps of all sequences and collect the selected frequencies</li>
                            <li>Plot the frequences' rates and indicate how many sequences share a frequence</li>
                        </ol>
                    </td>
                </tr>
                <tr>
                    <td><code>plot_prots_per_windist(database, out_file)</code></td>
                    <td>
                        <ol type="1">
                            <li>Collect the protein counts per hash, grouped by the hash's window distance</li>
                            <li>Plot boxes per window distance</li>
                        </ol>
                    </td>
                </tr>
            </table>
        </details>
    </li>
    <li><code>raincloud_plot.R</code> - A script to plot groups of values into a raincloud plot</li>
    <li><code>summary.py</code> - A script to summarize the output of <code>evaluation.py eval</code></li>
    <li><code>eval_times.py</code> - A script to fetch the durations for database creation</li>
</ul>

---
## Results (`results/*`)
|                          file                            |     content
|----------------------------------------------------------|------------------
|[summary.csv](./results/summary.csv)|a summary of the `_v0.4-exp-uniref_sampling/*.summary.csv` files

### Reproduce
In this repository, `protein.fa` is used to generate the database. You can extract the file from [this archive](https://github.com/usadellab/prot-fin/raw/5be77c4247327e3958c89200c03a938ec4734834/material/Mapman_reference_DB_202310.tar.bz2). The archive also includes `mapmanreferencebins.results.txt` which maps the proteins to their families.

The used table of Kidera factors is located in [../../materials/Amino_Acid_Kidera_Factors.csv](../../materials/Amino_Acid_Kidera_Factors.csv) and was generated by [this R-script](https://github.com/usadellab/prot-fin/blob/5be77c4247327e3958c89200c03a938ec4734834/methods/Amino_Acid_Kidera_Factors.R). (Read the [root-README](../../README.md) for more details).

[summary.csv](./results/summary.csv):
```diff
- requires _v0.4-exp-uniref_sampling/sample_WINSIZE_*.csv
```
```sh
cd methods
bash protfin_slurm.sh ../../../materials/protein.fa ../../../materials/mapmanreferencebins.results.txt
```
```diff
- wait until all jobs are finished, except the ones for window size 50 with overlap 49 and window size 40 with overlap 39, cancel these if their databases are created
```
```sh
python3 summary.py ../results/_v0.4-exp-uniref_sampling/*.summary.csv > ../results/summary.csv
```

---
## Discussion/Brainstorming
Compared to [previous](https://github.com/usadellab/prot-fin/blob/00571686e669166273509510169edde9f620ecf5/experiments/recog_with_fft/results/runtimes_createdb.csv) results, the database sizes are way lower. There seems to be a slight difference in average count of top scored matches (Average_Hits).

Some ideas for future development:
 - reduce database size (still too big, should be same as input 18 MB)
   - limit window distance appropriately (12 bits is way too much)

---
## Environment
<ul>
    <li><b>Personal</b><br>
        System: <code>Ubuntu 20.04.6 LTS</code>
        Shell: <code>zsh 5.8</code><br>
        <br>
        <table>
            <th>dependency</th><th>version</th>
            <tr><td>python3</td><td>3.8.10</td></tr>
            <tr><td>scipy</td><td>1.10.1</td></tr>
            <tr><td>numpy</td><td>1.23.0</td></tr>
            <tr><td>pandas</td><td>2.0.1</td></tr>
            <tr><td>tqdm</td><td>4.66.2</td></tr>
            <tr><td>matplotlib</td><td>3.5.2</td></tr>
            <tr><td>R</td><td>3.6.3</td></tr>
            <tr><td>tibble</td><td>3.2.1</td></tr>
            <tr><td>ggplot2</td><td>3.5.0</td></tr>
            <tr><td>ggdist</td><td>3.3.2</td></tr>
            <tr><td>dplyr</td><td>1.1.4</td></tr>
        </table>
    </li>
    <li><b>Slurm</b><br>
        System: <code>Ubuntu 22.04.4 LTS</code>
        Shell: <code>zsh 5.8.1</code><br>
        <br>
        <table>
            <th>dependency</th><th>version</th>
            <tr><td>slurm-wlm</td><td>21.08.5</td></tr>
            <tr><td>python3</td><td>3.10.12</td></tr>
            <tr><td>scipy</td><td>1.11.4</td></tr>
            <tr><td>numpy</td><td>1.26.2</td></tr>
            <tr><td>pandas</td><td>2.1.3</td></tr>
            <tr><td>tqdm</td><td>4.66.2</td></tr>
            <tr><td>matplotlib</td><td>3.8.2</td></tr>
            <tr><td>R</td><td>4.4.0</td></tr>
            <tr><td>tibble</td><td>3.2.1</td></tr>
            <tr><td>ggplot2</td><td>3.5.0</td></tr>
            <tr><td>ggdist</td><td>3.3.2</td></tr>
            <tr><td>dplyr</td><td>1.1.4</td></tr>
        </table>
    </li>
</ul>
